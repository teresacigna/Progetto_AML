{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import operator\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt \n",
    "from cv2 import cv2\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "import keras\n",
    "from keras import *\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions, VGG16\n",
    "from keras.preprocessing import image as kimage\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Activation, LeakyReLU\n",
    "\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, LeaveOneOut\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.applications import mobilenet_v2\n",
    "from tensorflow.keras.applications import vgg16\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications import efficientnet\n",
    "import efficientnet.keras as efn\n",
    "\n",
    "\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage.feature import hog\n",
    "\n",
    "from PIL import Image\n"
   ]
  },
  {
   "source": [
    "Si definisce una funzione per plottare accuracy e loss attraverso le epoche"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_plot = list(range(1,30+1))\n",
    "\n",
    "def plot_history(network_history):\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(x_plot, network_history.history['loss'])\n",
    "    plt.plot(x_plot, network_history.history['val_loss'])\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.plot(x_plot, network_history.history['accuracy'])\n",
    "    plt.plot(x_plot, network_history.history['val_accuracy'])\n",
    "    plt.legend(['Training', 'Validation'], loc='lower right')\n",
    "    plt.show()\n"
   ]
  },
  {
   "source": [
    "# Neural Network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Vengono creati train, test e validation generator, con un preprocessing sulle immagini uguale a quello attuato dalle reti pre-addestrate che si vogliono utilizzare sulle immagini di Imagenet."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "train_processing = keras.preprocessing.image.ImageDataGenerator(rotation_range=45, \n",
    "                                                                width_shift_range=0.1, \n",
    "                                                                height_shift_range=0.1, \n",
    "                                                                zoom_range=0.1, \n",
    "                                                                preprocessing_function=efficientnet.preprocess_input) ### mobilenet_v2, efficientnet\n",
    "train_generator= train_processing.flow_from_directory( \n",
    "    directory='mask_NEW_train_folders',\n",
    "    target_size=(224,224),\n",
    "    color_mode= 'rgb',\n",
    "    class_mode = 'categorical',\n",
    "    batch_size = 32,\n",
    "    shuffle = True,\n",
    "    seed = 1\n",
    ")"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_processing = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=efficientnet.preprocess_input) ### mobilenet_v2, efficientnet\n",
    "test_generator= test_processing.flow_from_directory(\n",
    "    directory='mask_NEW_test_folders',\n",
    "    target_size=(224,224),\n",
    "    color_mode= 'rgb',\n",
    "    class_mode = 'categorical',\n",
    "    batch_size = 32,\n",
    "    shuffle = True,\n",
    "    seed = 1\n",
    ")"
   ]
  },
  {
   "source": [
    "val_processing = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=efficientnet.preprocess_input) ### mobilenet_v2, efficientnet\n",
    "val_generator= val_processing.flow_from_directory(\n",
    "    directory='mask_NEW_val_folders',\n",
    "    target_size=(224,224),\n",
    "    color_mode= 'rgb',\n",
    "    class_mode = 'categorical',\n",
    "    batch_size = 32,\n",
    "    shuffle = True,\n",
    "    seed = 1\n",
    ")"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_net = efficientnet.EfficientNetB0(input_shape=(224,224,3), weights ='imagenet', include_top=False, pooling='avg') ## mobilenet_v2.MobileNetV2, efficientnet.EfficientNetB0, efficientnet.EfficientNetB2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_net.summary()"
   ]
  },
  {
   "source": [
    "## Rete iniziale"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layers in base_net.layers:\n",
    "    layers.trainable = False\n",
    "\n",
    "x = base_net.output \n",
    "\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "pred = keras.layers.Dense(102, activation='softmax')(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = keras.Model(inputs=base_net.input, outputs=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.compile(loss=keras.losses.categorical_crossentropy,\n",
    "            optimizer=keras.optimizers.Adam(), \n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = net.fit(train_generator, batch_size=64, epochs=30, verbose=1, validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = net.evaluate(test_generator)\n",
    "print(pred_test)\n",
    "pred_val = net.evaluate(val_generator)\n",
    "print(pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.save('effB0_NoRelu_Adam.h5')"
   ]
  },
  {
   "source": [
    "si calcola e si plotta la confusion matrix"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_processing = keras.preprocessing.image.ImageDataGenerator(preprocessing_function= efficientnet.preprocess_input)###resnet_v2 mobilenet_v2 vgg16\n",
    "test_generator= test_processing.flow_from_directory(\n",
    "    directory='mask_NEW_test_folders',\n",
    "    target_size=(224,224), #scelta standard\n",
    "    color_mode= 'rgb', #dobbiamo mettere stessi parametri della rete di partenza\n",
    "    class_mode = 'categorical',\n",
    "    batch_size = 1020,\n",
    "    shuffle = True,\n",
    "    seed = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, yc_test = next(test_generator)\n",
    "y_test = np.argmax(yc_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test,  verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test, y_pred_bool)\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)"
   ]
  },
  {
   "source": [
    "## Rete completa"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layers in base_net.layers:\n",
    "    layers.trainable = False\n",
    "    \n",
    "x = base_net.output \n",
    "\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(128, activation = 'relu', kernel_regularizer=regularizers.l2(0.0005))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "pred = keras.layers.Dense(102, activation='softmax')(x) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = keras.Model(inputs=base_net.input, outputs=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.compile(loss=keras.losses.categorical_crossentropy,\n",
    "            optimizer=keras.optimizers.Adam(), \n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = net.fit(train_generator, batch_size=64, epochs=30, verbose=1, validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = net.evaluate(test_generator)\n",
    "print(pred_test)\n",
    "pred_val = net.evaluate(val_generator)\n",
    "print(pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.save('effB0_Relu_Adam.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_processing = keras.preprocessing.image.ImageDataGenerator(preprocessing_function= efficientnet.preprocess_input)###resnet_v2 mobilenet_v2 vgg16\n",
    "test_generator= test_processing.flow_from_directory(\n",
    "    directory='mask_NEW_test_folders',\n",
    "    target_size=(224,224), #scelta standard\n",
    "    color_mode= 'rgb', #dobbiamo mettere stessi parametri della rete di partenza\n",
    "    class_mode = 'categorical',\n",
    "    batch_size = 1020,\n",
    "    shuffle = True,\n",
    "    seed = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, yc_test = next(test_generator)\n",
    "y_test = np.argmax(yc_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test,  verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test, y_pred_bool)\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)"
   ]
  },
  {
   "source": [
    "# SVM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Si importa la rete pre-addestrata scelta"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = efficientnet.EfficientNetB0(include_top=False, weights='imagenet', pooling='avg', input_shape=(224,224,3)) ## mobilenet_v2.MobileNetV2, efficientnet.EfficientNetB0, efficientnet.EfficientNetB2"
   ]
  },
  {
   "source": [
    "neural features: utilizza la rete scelta, per classificare l'immagine fornita in input, dopo aver applicato lo stesso preprocessing applicato dalla rete alle immagini di Imagenet\n",
    "\n",
    "get_colors: dopo avere approssimato ogni colore dell'immagine fornita al colore RGB limite pi√π vicino, calcola la percentuale di blu, rosso e verde contenuta nell'immagine\n",
    "\n",
    "hog_image: calcola l'HoG dell'immagine utilizzando 8 direzioni\n",
    "\n",
    "lbp_image_2: applica un LBP di raggio 5, che considera 8 punti sul raggio\n",
    "\n",
    "combo_xxx: combina le features indicate nel nome\n",
    "\n",
    "load_data: carica i dati calcolando le features indicate in 'feature extractor'"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_features(image_path):\n",
    "    img = kimage.load_img(image_path, target_size=(224, 224))\n",
    "    x = kimage.img_to_array(img)\n",
    "    x = efficientnet.preprocess_input(x) #mobilenet_v2, efficientnet\n",
    "    x = np.expand_dims(x, axis = 0)\n",
    "    features = net.predict(x) #viene utilizzata la rete importata all'inizio del chunk\n",
    "    features = features.flatten()   \n",
    "    return features\n",
    "\n",
    "def get_colors (image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    _, img = cv2.threshold(img, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    color = ('b','g','r')\n",
    "    qtdBlue = 0\n",
    "    qtdGreen = 0\n",
    "    qtdRed = 0\n",
    "    totalPixels = 0\n",
    "\n",
    "    for channel,_ in enumerate(color):\n",
    "        histr = cv2.calcHist([img],[channel],None,[256],[1,256])\n",
    "        totalPixels+=sum(histr)\n",
    "        if channel==0:\n",
    "            qtdBlue = sum(histr)\n",
    "        elif channel==1:\n",
    "            qtdGreen = sum(histr)\n",
    "        elif channel==2:\n",
    "            qtdRed = sum(histr)\n",
    "\n",
    "    qtdBlue = (qtdBlue/totalPixels)*100\n",
    "    qtdGreen = (qtdGreen/totalPixels)*100\n",
    "    qtdRed = (qtdRed/totalPixels)*100\n",
    "\n",
    "    if math.isnan(qtdBlue) == True :\n",
    "        qtdBlue = np.zeros(1)\n",
    "    if math.isnan(qtdGreen) == True :\n",
    "        qtdGreen = np.zeros(1)\n",
    "    if math.isnan(qtdRed) == True :\n",
    "        qtdRed = np.zeros(1)\n",
    "\n",
    "    colors = np.asarray([qtdBlue[0], qtdGreen[0], qtdRed[0]])\n",
    "    return colors\n",
    "\n",
    "def hog_image (image_path):\n",
    "    image = kimage.load_img(image_path, target_size= (224,224))\n",
    "    features, _ = hog(image, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(1, 1), visualize=True, multichannel=True)\n",
    "\n",
    "    return features\n",
    "\n",
    "def lbp_image_2 (image_path):\n",
    "\n",
    "    img_bgr = cv2.imread(image_path)\n",
    "    img_bgr = cv2.resize(img_bgr, (100,100)) \n",
    "    img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "    lbp = local_binary_pattern(img_gray, 8,5 , \"uniform\")\n",
    "\n",
    "    lbp_array_flat = lbp_array.flatten(lbp)\n",
    "\n",
    "    return lbp_array_flat\n",
    "\n",
    "def combo_neural_colors_hog(image_path):\n",
    "\n",
    "    neural = neural_features (image_path)\n",
    "\n",
    "    colors = get_colors(image_path)\n",
    "    \n",
    "    hog = hog_image (image_path)\n",
    "    \n",
    "    return np.concatenate((colors, neural, hog))\n",
    "\n",
    "def combo_neural_colors_hog_lbp(image_path):\n",
    "\n",
    "    neural = neural_features (image_path)\n",
    "\n",
    "    colors = get_colors(image_path)\n",
    "    \n",
    "    hog = hog_image (image_path)\n",
    "    \n",
    "    lbp = lbp_image_2 (image_path)\n",
    "    \n",
    "    return np.concatenate((colors, neural, hog, lbp))\n",
    "\n",
    "def combo_colors_hog_lbp(image_path):\n",
    "\n",
    "    lbp = lbp_image_2 (image_path)\n",
    "\n",
    "    colors = get_colors(image_path)\n",
    "    \n",
    "    hog = hog_image (image_path)\n",
    "    \n",
    "    return np.concatenate((colors, lbp, hog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity(image_path):\n",
    "    img = kimage.load_img(image_path, target_size=(224, 224), color_mode= 'rgb')\n",
    "    x = kimage.img_to_array(img)\n",
    "    x = efficientnet.preprocess_input(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def load_data(folder, feature_extractor=identity, maximages = 'default' ):\n",
    "    if maximages == 'default':\n",
    "        maximages = len(os.listdir(folder))+1\n",
    "\n",
    "    base_path = folder\n",
    "\n",
    "    features = []\n",
    "\n",
    "    for index, image in enumerate(sorted(os.listdir(base_path))):\n",
    "        print ('image', index)\n",
    "        if index < maximages:\n",
    "            image_path = base_path+image\n",
    "            # Load file and extract features\n",
    "            cur_features = feature_extractor(image_path)\n",
    "            #cur_features = cur_features.flatten()\n",
    "            features.append(cur_features)\n",
    "\n",
    "    #features = np.array(features)\n",
    "    return features"
   ]
  },
  {
   "source": [
    "Inizialmente si crea un dataset con le features estratte dal 'feature_extractor' scelto"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "X_train_features = load_data('mask_NEW_train/',feature_extractor=combo_neural_colors_hog)\n",
    "with open('X_train_features_neural_colors_hog.pickle', 'wb') as handle:\n",
    "    pickle.dump(X_train_features, handle)\n",
    "X_test_features = load_data(feature_extractor=combo_neural_colors_hog, folder = 'mask_NEW_test/')\n",
    "with open('X_test_features_neural_colors_hog.pickle', 'wb') as handle:\n",
    "    pickle.dump(X_test_features, handle)\n",
    "X_val_features = load_data(feature_extractor=combo_neural_colors_hog, folder = 'mask_NEW_val/')\n",
    "with open('X_val_features_neural_colors_hog.pickle', 'wb') as handle:\n",
    "    pickle.dump(X_val_features, handle)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('102flowers_y_train.pickle', 'rb') as handle:\n",
    "    y_train = pickle.load(handle)\n",
    "num_classes = 102\n",
    "yc_train = keras.utils.to_categorical(y_train-1, num_classes)\n",
    "with open ('102flowers_y_test.pickle', 'rb') as handle:\n",
    "    y_test = pickle.load(handle)\n",
    "num_classes = 102\n",
    "yc_test = keras.utils.to_categorical(y_test-1, num_classes)\n",
    "with open ('102flowers_y_val.pickle', 'rb') as handle:\n",
    "    y_val = pickle.load(handle)\n",
    "num_classes = 102\n",
    "yc_val = keras.utils.to_categorical(y_val-1, num_classes)\n",
    "with open ('102flowers_y_test_val.pickle', 'rb') as handle:\n",
    "    y_test_val = pickle.load(handle)\n",
    "num_classes = 102\n",
    "yc_test_val = keras.utils.to_categorical(y_test_val-1, num_classes)"
   ]
  },
  {
   "source": [
    "with open('X_test_features_neural_colors_hog.pickle', 'rb') as handle:\n",
    "    X_test_features = pickle.load(handle)\n",
    "with open('X_train_features_neural_colors_hog.pickle', 'rb') as handle:\n",
    "    X_train_features = pickle.load(handle)\n",
    "with open('X_val_features_neural_colors_hog.pickle', 'rb') as handle:\n",
    "    X_val_features = pickle.load(handle)\n",
    "with open('X_test_val_features_neural_colors_hog.pickle', 'rb') as handle:\n",
    "    X_test_val_features = pickle.load(handle)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "si impostano empricamente C e gamma tenendo conto che un C basso implica una forte regolarizzazione"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = SVC(kernel='poly',  degree=2, class_weight='balanced', C = 0.8, gamma = 0.005)\n",
    "print('fit...')\n",
    "clf2=clf2.fit(X_train_features, y_train)\n",
    "print('predict...')\n",
    "y2_pred = clf2.predict(X_train_features)\n",
    "\n",
    "print(classification_report(y_train, y2_pred))\n",
    "\n",
    "with open('svc_neural_efficient_C08G0005.pickle', 'wb') as handle:\n",
    "    pickle.dump(clf2, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = clf2.predict(X_test_features)\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "y_pred_val = clf2.predict(X_val_features)\n",
    "print(classification_report(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test, y_pred_test)\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)"
   ]
  }
 ]
}